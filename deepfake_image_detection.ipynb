{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XpSCruPQleG"
      },
      "outputs": [],
      "source": [
        "#import gradio as gr\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "mtcnn = MTCNN(\n",
        "    select_largest=False, #select_largest: This parameter is set to False. When set to True, it would select the largest face detected when multiple faces are present in an image\n",
        "    post_process=False, #post_process: This parameter is set to False. When set to True, it applies a post-processing step to refine the bounding boxes of the detected faces.\n",
        "    device=DEVICE\n",
        ").to(DEVICE).eval() #eval() is called on the MTCNN object. This sets the model to evaluation mode,\n",
        "# which is important when using pre-trained models, as it disables certain operations like dropout and batch normalization during inference."
      ],
      "metadata": {
        "id": "izxV8X5FQ7ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pretrained: This parameter is set to \"vggface2\", which means the model will be initialized with weights pre-trained on the VGGFace2 dataset.\n",
        "#VGGFace2 is a large-scale face recognition dataset.\n",
        "model = InceptionResnetV1(\n",
        "    pretrained=\"vggface2\",\n",
        "    classify=True,\n",
        "    num_classes=1, # num_classes parameter to 1 in the provided code implies that the InceptionResnetV1 model is being used for a binary classification task.\n",
        "    device=DEVICE\n",
        ")\n",
        "#Load Model Weights:\n",
        "checkpoint = torch.load(\"resnetinceptionv1_epoch_32.pth\", map_location=torch.device('cpu'))\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(DEVICE)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "p1we44fsQ8Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the function generates a visualization of the attention region of the model using\n",
        "# GradCAM (Gradient-weighted Class Activation Mapping) to highlight the important regions in the image that contribute to the model's prediction.\n",
        "#https://medium.com/@mohamedchetoui/grad-cam-gradient-weighted-class-activation-mapping-ffd72742243a\n",
        "\n",
        "def predict(input_image:Image.Image):\n",
        "    \"\"\"Predict the label of the input_image\"\"\"\n",
        "    face = mtcnn(input_image)\n",
        "    if face is None:\n",
        "        raise Exception('No face detected')\n",
        "    face = face.unsqueeze(0) # add the batch dimension\n",
        "    face = F.interpolate(face, size=(256, 256), mode='bilinear', align_corners=False) #The detected face is resized to a fixed size of (256, 256) using bilinear interpolation\n",
        "\n",
        "    # convert the face into a numpy array to be able to plot it\n",
        "    prev_face = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
        "    prev_face = prev_face.astype('uint8')\n",
        "\n",
        "    face = face.to(DEVICE)\n",
        "    face = face.to(torch.float32)\n",
        "    face = face / 255.0\n",
        "    face_image_to_plot = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
        "\n",
        "    target_layers=[model.block8.branch1[-1]]\n",
        "    use_cuda = True if torch.cuda.is_available() else False\n",
        "    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=use_cuda) #gradient weighted class activation mapping\n",
        "    targets = [ClassifierOutputTarget(0)]\n",
        "\n",
        "    grayscale_cam = cam(input_tensor=face, targets=targets, eigen_smooth=True)\n",
        "    grayscale_cam = grayscale_cam[0, :]\n",
        "    visualization = show_cam_on_image(face_image_to_plot, grayscale_cam, use_rgb=True)\n",
        "    face_with_mask = cv2.addWeighted(prev_face, 1, visualization, 0.5, 0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = torch.sigmoid(model(face).squeeze(0))\n",
        "        prediction = \"real\" if output.item() < 0.5 else \"fake\"\n",
        "\n",
        "        real_prediction = 1 - output.item()\n",
        "        fake_prediction = output.item()\n",
        "\n",
        "        confidences = {\n",
        "            'real': real_prediction,\n",
        "            'fake': fake_prediction\n",
        "        }\n",
        "    return confidences, face_with_mask\n"
      ],
      "metadata": {
        "id": "vbIxICSbQ_R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interface = gr.Interface(\n",
        "#     fn=predict,\n",
        "#     inputs=[\n",
        "#         gr.inputs.Image(label=\"Input Image\", type=\"pil\")\n",
        "#     ],\n",
        "#     outputs=[\n",
        "#         gr.outputs.Label(label=\"Class\"),\n",
        "#         gr.outputs.Image(label=\"Face with Explainability\", type=\"pil\")\n",
        "#     ],\n",
        "# ).launch()"
      ],
      "metadata": {
        "id": "d3BVMhzeRCqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Assuming you have initialized the model and imported the required modules\n",
        "# model = initialize_your_model()\n",
        "# mtcnn = initialize_mtcnn()\n",
        "# GradCAM = initialize_GradCAM()\n",
        "# ClassifierOutputTarget = initialize_ClassifierOutputTarget()\n",
        "\n",
        "def predict(input_image:Image.Image):\n",
        "    \"\"\"Predict the label of the input_image\"\"\"\n",
        "    face = mtcnn(input_image)\n",
        "    if face is None:\n",
        "        raise Exception('No face detected')\n",
        "    face = face.unsqueeze(0) # add the batch dimension\n",
        "    face = F.interpolate(face, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "\n",
        "    # convert the face into a numpy array to be able to plot it\n",
        "    prev_face = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
        "    prev_face = prev_face.astype('uint8')\n",
        "\n",
        "    face = face.to(DEVICE)\n",
        "    face = face.to(torch.float32)\n",
        "    face = face / 255.0\n",
        "    face_image_to_plot = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
        "\n",
        "    target_layers=[model.block8.branch1[-1]]\n",
        "    use_cuda = True if torch.cuda.is_available() else False\n",
        "    cam = GradCAM(model=model, target_layers=target_layers, use_cuda=use_cuda)\n",
        "    targets = [ClassifierOutputTarget(0)]\n",
        "\n",
        "    grayscale_cam = cam(input_tensor=face, targets=targets, eigen_smooth=True)\n",
        "    grayscale_cam = grayscale_cam[0, :]\n",
        "    visualization = show_cam_on_image(face_image_to_plot, grayscale_cam, use_rgb=True)\n",
        "    face_with_mask = cv2.addWeighted(prev_face, 1, visualization, 0.5, 0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = torch.sigmoid(model(face).squeeze(0))\n",
        "        prediction = \"real\" if output.item() < 0.5 else \"fake\"\n",
        "\n",
        "        real_prediction = 1 - output.item()\n",
        "        fake_prediction = output.item()\n",
        "\n",
        "        confidences = {\n",
        "            'real': real_prediction,\n",
        "            'fake': fake_prediction\n",
        "        }\n",
        "    return confidences, face_with_mask\n",
        "\n",
        "\n",
        "def classify_image(image_path):\n",
        "    input_image = Image.open(image_path)\n",
        "\n",
        "    try:\n",
        "        confidences, _ = predict(input_image)\n",
        "\n",
        "        # Determine the final prediction based on the confidence scores\n",
        "        if confidences['real'] > confidences['fake']:\n",
        "            prediction = \"real\"\n",
        "            confidence_percentage = confidences['real'] * 100\n",
        "        else:\n",
        "            prediction = \"fake\"\n",
        "            confidence_percentage = confidences['fake'] * 100\n",
        "\n",
        "        print(\"Prediction:\", prediction)\n",
        "        print(\"Confidence:\", confidence_percentage)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", str(e))\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = r\"C:\\Users\\kaush\\Downloads\\WhatsApp Image 2023-01-07 at 9.51.50 PM.jpeg\"  # image path\n",
        "    classify_image(image_path)\n",
        "    #https://www.nytimes.com/2023/01/22/business/media/deepfake-regulation-difficulty.html"
      ],
      "metadata": {
        "id": "i0rYp-XVRGrr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}